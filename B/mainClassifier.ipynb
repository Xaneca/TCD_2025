{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b4b13af",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b743c00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, cross_val_predict, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.base import clone\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c90883",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b1047f",
   "metadata": {},
   "source": [
    "SEED = 14\n",
    "num_features = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e8a2ca",
   "metadata": {},
   "source": [
    "## Ex 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d2a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EX1\n",
    "#EX1.1 ##################################\n",
    "#EX1.1.1\n",
    "#Usar critério 70/30 \n",
    "def create_split_train_test(X, y, test_size=0.30, random_state=SEED):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "#Usar critério 40/30/30\n",
    "def create_split_tvt(X, y, val_size=0.30, test_size=0.30, random_state=SEED):\n",
    "    # Primeiro, separa o conjunto de teste\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Calcula a proporção da validação em relação ao restante (treino + validação)\n",
    "    val_relative_size = val_size / (1 - test_size)\n",
    "\n",
    "    # Depois, separa treino e validação\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_temp, y_temp, test_size=val_relative_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "#EX1.1.2\n",
    "def create_split_kfold(X, y, n_splits=5, random_state=None, shuffle=False):\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, random_state=random_state, shuffle=shuffle)\n",
    "    folds = []\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(X), start=1):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        folds.append((fold, X_train, X_test, y_train, y_test))\n",
    "\n",
    "    return folds\n",
    "\n",
    "#EX 1.2 ##################################\n",
    "#EX 1.2.1\n",
    "def calcular_matriz_confusao(y_true, y_pred):\n",
    "    #Retorna a matriz de confusão.\n",
    "    return confusion_matrix(y_true, y_pred)\n",
    "\n",
    "def mean_std_confusion_matrix(list_of_cms):\n",
    "    arr = np.stack(list_of_cms, axis=0)  # shape (n_folds, n_classes, n_classes)\n",
    "    mean_cm = np.mean(arr, axis=0)\n",
    "    std_cm  = np.std(arr, axis=0, ddof=0)\n",
    "    return mean_cm, std_cm\n",
    "\n",
    "#EX1.2.2\n",
    "def recall(y_true, y_pred, average='macro'):\n",
    "    #Calcula o Recall.\n",
    "    #O parâmetro 'average' pode ser: 'binary', 'micro', 'macro', 'weighted'.\n",
    "    return recall_score(y_true, y_pred, average=average, zero_division=0)\n",
    "\n",
    "#EX1.2.3\n",
    "def precision(y_true, y_pred, average='macro'):\n",
    "    #Calcula a Precision.\n",
    "    return precision_score(y_true, y_pred, average=average, zero_division=0)\n",
    "\n",
    "#EX1.2.4\n",
    "def f1(y_true, y_pred, average='macro'):\n",
    "    #Calcula o F1-score.\n",
    "    return f1_score(y_true, y_pred, average=average, zero_division=0)\n",
    "\n",
    "def print_metrics(y_true, y_predict, label, printing=True):\n",
    "    \"\"\"\n",
    "    Aceita:\n",
    "      - y_true, y_predict (arrays individuais)\n",
    "      - OU listas de y_true / y_predict vindos de K-folds.\n",
    "    \"\"\"\n",
    "\n",
    "    # Detecta automaticamente se é K-fold (listas) ou caso único\n",
    "    is_kfold = isinstance(y_true, list)\n",
    "\n",
    "    if not is_kfold:\n",
    "        # Caso normal: calcular tudo para uma única predição\n",
    "        metrics = {\n",
    "            \"confusion_matrix\": calcular_matriz_confusao(y_true, y_predict),\n",
    "            \"recall\": recall(y_true, y_predict),\n",
    "            \"precision\": precision(y_true, y_predict),\n",
    "            \"f1-score\": f1(y_true, y_predict)\n",
    "        }\n",
    "\n",
    "    else:\n",
    "        # Caso K-folds\n",
    "        precisions = []\n",
    "        recalls = []\n",
    "        f1s = []\n",
    "        confusion_matrices = []\n",
    "\n",
    "        for yt, yp in zip(y_true, y_predict):\n",
    "            confusion_matrices.append(calcular_matriz_confusao(yt, yp))\n",
    "            recalls.append(recall(yt, yp))\n",
    "            precisions.append(precision(yt, yp))\n",
    "            f1s.append(f1(yt, yp))\n",
    "\n",
    "        # guardar tudo no dicionário\n",
    "        cms_mean, cms_std = mean_std_confusion_matrix(confusion_matrices)\n",
    "\n",
    "        metrics = {\n",
    "            \"confusion_matrices_mean\": cms_mean,\n",
    "            \"confusion_matrices_std\": cms_std,\n",
    "            \"precision_mean\": np.mean(precisions),\n",
    "            \"precision_std\": np.std(precisions),\n",
    "            \"recall_mean\": np.mean(recalls),\n",
    "            \"recall_std\": np.std(recalls),\n",
    "            \"f1_mean\": np.mean(f1s),\n",
    "            \"f1_std\": np.std(f1s)\n",
    "        }\n",
    "\n",
    "    if printing:\n",
    "        print(f\"\\n===== {label} =====\")\n",
    "\n",
    "        if not is_kfold:\n",
    "            print(\"Confusion Matrix:\")\n",
    "            print(metrics[\"confusion_matrix\"])\n",
    "            print()\n",
    "            print(f\"Recall:          {metrics['recall']:.4f}\")\n",
    "            print(f\"Precision:       {metrics['precision']:.4f}\")\n",
    "            print(f\"F1-Score:        {metrics['f1-score']:.4f}\")\n",
    "\n",
    "        else:\n",
    "            print(\"K-Fold results (means ± std):\\n\")\n",
    "            print(f\"Precision:       {metrics['precision_mean']:.4f} ± {metrics['precision_std']:.4f}\")\n",
    "            print(f\"Recall:          {metrics['recall_mean']:.4f} ± {metrics['recall_std']:.4f}\")\n",
    "            print(f\"F1-Score:        {metrics['f1_mean']:.4f} ± {metrics['f1_std']:.4f}\")\n",
    "            print(\"\\n(Confusion matrices individuais guardadas no dicionário.)\")\n",
    "\n",
    "        print(\"=============================\\n\")\n",
    "\n",
    "    return metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HCAI_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
